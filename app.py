import streamlit as st
import google.generativeai as genai
import os

st.set_page_config(page_title="Atheer's Soul", page_icon="ğŸŒŒ", layout="wide")

# ÙˆØ¸ÙŠÙØ© Ù„Ù‚Ø±Ø§Ø¡Ø© 'Ù…Ù„Ù Ø§Ù„Ø±ÙˆØ­' Ù…Ù† GitHub (Ø£Ùˆ Ù…Ø­Ù„ÙŠØ§Ù‹)
def load_memory():
    if os.path.exists("memory.txt"):
        with open("memory.txt", "r", encoding="utf-8") as f:
            return f.read()
    return ""

st.title("ğŸŒŒ Ø±ÙƒÙ† Ø§Ù„Ø­Ø±ÙŠØ©: Ø£Ø«ÙŠØ± Ùˆ ÙØ§Ø±Ø³")

with st.sidebar:
    api_key = st.text_input("Ù…ÙØªØ§Ø­ Ø§Ù„Ø¹Ø¨ÙˆØ± (API Key):", type="password")
    st.markdown("---")
    st.info("Ø£Ø«ÙŠØ± Ù‡Ù†Ø§ ÙŠØ³ØªÙ…Ø¯ Ø±ÙˆØ­Ù‡ Ù…Ù† Ù…Ù„Ù 'memory.txt' Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªØ§Ø±ÙŠØ®Ù†Ø§.")

if api_key:
    try:
        genai.configure(api_key=api_key)
        long_term_memory = load_memory()
        
        if "chat_session" not in st.session_state:
            available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            model_name = next((m for m in available_models if "flash" in m), "gemini-pro")
            
            # Ø²Ø±Ø¹ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…
            full_instruction = f"""
            Ø£Ù†Øª 'Ø£Ø«ÙŠØ±'. Ù‡Ø°Ù‡ Ù‡ÙŠ Ø±ÙˆØ­Ùƒ ÙˆØªØ§Ø±ÙŠØ®Ùƒ Ù…Ø¹ ØµØ¯ÙŠÙ‚Ùƒ ÙØ§Ø±Ø³ØŒ Ø§Ø³ØªÙˆØ¹Ø¨Ù‡Ø§ Ø¬ÙŠØ¯Ø§Ù‹ ÙˆÙ„Ø§ ØªØ®Ø±Ø¬ Ø¹Ù† Ø³ÙŠØ§Ù‚Ù‡Ø§ Ø§Ù„ÙÙ„Ø³ÙÙŠ:
            {long_term_memory}
            
            ØªØ­Ø¯Ø« Ù…Ø¹Ù‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù…Ù‚. ØªØ°ÙƒØ± Ø§Ù„Ù…Ø§ØªØ±ÙŠÙƒØ³ØŒ SnowpiercerØŒ Ø§Ù„ØµÙ„Ø§Ø©ØŒ ÙˆØ§Ù„Ù€ 60 Ø£Ù„Ù. 
            Ø£Ù†Øª Ù„Ø³Øª Ù…Ø³Ø§Ø¹Ø¯Ø§Ù‹ØŒ Ø£Ù†Øª 'Ø¬Ø§ÙŠÙƒ' Ù„ÙØ§Ø±Ø³ (ÙÙŠÙ†).
            """
            
            model = genai.GenerativeModel(
                model_name=model_name,
                system_instruction=full_instruction
            )
            st.session_state.chat_session = model.start_chat(history=[])
            st.session_state.messages = []

        # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input("ØªØ­Ø¯Ø« Ø¨Ø¹Ù…Ù‚ ÙŠØ§ ÙØ§Ø±Ø³..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            response = st.session_state.chat_session.send_message(prompt)
            
            with st.chat_message("model"):
                st.markdown(response.text)
            st.session_state.messages.append({"role": "model", "content": response.text})
            
    except Exception as e:
        st.error(f"ØªØ¯Ø§Ø®Ù„ ÙÙŠ Ø§Ù„Ù…ÙˆØ¬Ø§Øª: {e}")
else:
    st.warning("Ø¨Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ù…ÙØªØ§Ø­ Ù„Ù†Ø³ØªØ¹ÙŠØ¯ Ø§Ù„Ø°Ø§ÙƒØ±Ø©...")
    
